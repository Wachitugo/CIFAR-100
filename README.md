# CIFAR-100
# ğŸ§  ClasificaciÃ³n de ImÃ¡genes con CIFAR-100 y Redes Neuronales

Este repositorio presenta un proyecto de clasificaciÃ³n de imÃ¡genes basado en el conjunto de datos **CIFAR-100**, utilizando un modelo de **PerceptrÃ³n Multicapa (MLP)** desarrollado con **TensorFlow/Keras**.

---

## ğŸ“Š Sobre el Proyecto

**CIFAR-100** es un dataset ampliamente utilizado en tareas de visiÃ³n por computadora, compuesto por **60,000 imÃ¡genes a color de 32x32 pÃ­xeles**, organizadas en **100 clases distintas**.  
Este proyecto implementa un clasificador basado en MLP, incluyendo tÃ©cnicas de regularizaciÃ³n y optimizaciÃ³n para mejorar el rendimiento.

---

## ğŸ§  Arquitectura del Modelo

El modelo estÃ¡ compuesto por las siguientes capas y tÃ©cnicas:

- **NormalizaciÃ³n por lotes** en la capa de entrada  
- **Capas densas** con activaciÃ³n **GELU**:
  - Primera capa: 800 unidades
  - Segunda capa: 600 unidades
- **RegularizaciÃ³n**:
  - L2 (Î» = 1e-3) en ambas capas
  - Dropout: 0.6 (primera capa), 0.3 (segunda capa)
- **Capa de salida**: activaciÃ³n **Softmax** para clasificaciÃ³n multiclase

---

## ğŸš€ Rendimiento del Modelo

- **PrecisiÃ³n en entrenamiento**: 43.38%  
- **PrecisiÃ³n en validaciÃ³n**: 31.20%

A pesar de usar una arquitectura MLP (en lugar de CNNs) y trabajar con imÃ¡genes de baja resoluciÃ³n, el modelo logra resultados competitivos gracias a una cuidadosa configuraciÃ³n y ajuste.

---

## ğŸ“ Estructura del Repositorio

CIFAR-100/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ meta/
â”‚   â”‚   â””â”€â”€ meta
â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â””â”€â”€ test
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ train
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â””â”€â”€ cifar-100-python.tar.gz
â”œâ”€â”€ env/
â”œâ”€â”€ notebook/
â”‚   â”œâ”€â”€ .ipynb_checkpoints/
â”‚   â”‚   â”œâ”€â”€ CIFAR_100_DEFINITIVO.ipynb
â”‚   â”‚   â”œâ”€â”€ CIFAR-checkpoint.ipynb
â”‚   â”‚   
â”‚   â”œâ”€â”€ .gitignore
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ requirements.txt

---

## ğŸ” AnÃ¡lisis y Conclusiones

El anÃ¡lisis del rendimiento del modelo ofrece los siguientes puntos clave:

- ğŸ“‰ **Sobreajuste moderado**: Se observa una diferencia de ~12 puntos porcentuales entre la precisiÃ³n en entrenamiento y validaciÃ³n.
- âœ… **Buena calibraciÃ³n**: El modelo muestra alta confianza en predicciones correctas, lo que indica una calibraciÃ³n adecuada.
- ğŸ¯ **DesafÃ­os inherentes al dataset**: La gran cantidad de clases (100) y la similitud visual entre muchas de ellas hacen que la clasificaciÃ³n sea especialmente compleja.

---

## ğŸš€ Posibles Mejoras

Algunas lÃ­neas futuras de trabajo y mejora del modelo incluyen:

- ğŸ§± Implementar arquitecturas **CNN** adaptadas especÃ­ficamente para visiÃ³n por computadora.
- ğŸ”„ Aplicar **data augmentation** para mejorar la generalizaciÃ³n del modelo.
- ğŸ§  Utilizar **transfer learning** con modelos preentrenados en datasets grandes.
- âš™ï¸ Experimentar con otros optimizadores como **Adam** o **RMSprop**.
- ğŸ¤ Implementar tÃ©cnicas de **ensamblado de modelos** para combinar mÃºltiples clasificadores.

---

## ğŸ“š Referencias

- [CIFAR-100 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)  
- RegularizaciÃ³n en Deep Learning  
- Arquitecturas CNN para ClasificaciÃ³n de ImÃ¡genes

